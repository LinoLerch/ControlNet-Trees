{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Root directory ControlNet-Trees\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "ROOT_DIR_GIS = os.path.join(ROOT_DIR, 'Google-Image-Scraper')\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR_GIS,'photos','tree_steps')\n",
    "\n",
    "\n",
    "DATASET_DIR = os.path.join(ROOT_DIR_GIS, 'photos','tree_dataset')\n",
    "DATASET_DIR_TEST = os.path.join(ROOT_DIR_GIS, 'photos','test_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred in image c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\Google-Image-Scraper\\photos\\10k\\baum wallpaper hd\\baumwallpaperhd150.jpeg: cannot write mode CMYK as PNG\n",
      "An error occurred in image c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\Google-Image-Scraper\\photos\\10k\\baum wallpaper hd\\baumwallpaperhd245.jpeg: cannot write mode CMYK as PNG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'baum wallpaper hd' added to Dataset (new size 426 images)\n",
      "Folder 'einzelner baum foto' added to Dataset (new size 468 images)\n",
      "Folder 'full apple tree images' added to Dataset (new size 510 images)\n",
      "Folder 'full ceder tree image' added to Dataset (new size 546 images)\n",
      "Folder 'full elm tree' added to Dataset (new size 575 images)\n",
      "Folder 'full fir tree image' added to Dataset (new size 608 images)\n",
      "Folder 'full hickory tree images' added to Dataset (new size 644 images)\n",
      "Folder 'full mango tree images hd' added to Dataset (new size 1174 images)\n",
      "Folder 'full maple tree images' added to Dataset (new size 1405 images)\n",
      "Folder 'full orange tree images' added to Dataset (new size 2058 images)\n",
      "Folder 'full sycamore tree images' added to Dataset (new size 2301 images)\n",
      "Folder 'Lone tree freepik' added to Dataset (new size 2442 images)\n",
      "Folder 'Lone tree getty images' added to Dataset (new size 2488 images)\n",
      "Folder 'Lone tree istock images' added to Dataset (new size 2537 images)\n",
      "Folder 'lone tree pinterest' added to Dataset (new size 2767 images)\n",
      "Folder 'Lone tree shutterstock images' added to Dataset (new size 3059 images)\n",
      "Folder 'Lone tree vecteezy' added to Dataset (new size 3089 images)\n",
      "Folder 'lonely tree wallpaper' added to Dataset (new size 3530 images)\n",
      "Folder 'oak tree wallpaper' added to Dataset (new size 3930 images)\n",
      "An error occurred in image c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\Google-Image-Scraper\\photos\\10k\\single baobab tree\\singlebaobabtree108.jpeg: cannot write mode CMYK as PNG\n",
      "An error occurred in image c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\Google-Image-Scraper\\photos\\10k\\single baobab tree\\singlebaobabtree109.jpeg: cannot write mode CMYK as PNG\n",
      "Folder 'single baobab tree' added to Dataset (new size 4182 images)\n",
      "Folder 'single beech tree' added to Dataset (new size 4536 images)\n",
      "Folder 'single birch tree' added to Dataset (new size 4571 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\rembg\\sessions\\base.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  im_ary = im_ary / np.max(im_ary)\n",
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\rembg\\sessions\\u2net.py:29: RuntimeWarning: invalid value encountered in cast\n",
      "  mask = Image.fromarray((pred * 255).astype(\"uint8\"), mode=\"L\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'single pine tree hd images' added to Dataset (new size 4610 images)\n",
      "Folder 'single tree image hd' added to Dataset (new size 5146 images)\n",
      "Folder 'single tree pexels' added to Dataset (new size 5266 images)\n",
      "Folder 'single tree photography' added to Dataset (new size 5524 images)\n",
      "Folder 'single tree unsplash' added to Dataset (new size 5768 images)\n",
      "Folder 'single tree wallpaper phone' added to Dataset (new size 6001 images)\n",
      "Folder 'tree on field image' added to Dataset (new size 6245 images)\n",
      "Folder 'tree photo' added to Dataset (new size 6283 images)\n",
      "Folder 'tree photography' added to Dataset (new size 7010 images)\n",
      "Folder 'weeping cherry tree' added to Dataset (new size 7048 images)\n"
     ]
    }
   ],
   "source": [
    "# All image folders from scraping\n",
    "from build_dataset import build_dataset_from_folder\n",
    "\n",
    "in_folder = os.path.join(ROOT_DIR_GIS, 'photos','10k')\n",
    "\n",
    "build_dataset_from_folder(in_folder, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buiding / extending dataset (current size: 11370 images)\n",
      "Folder 1 of 23 'Acer palmatum' added to Dataset (new size 11391 images)\n",
      "Folder 2 of 23 'Cedrus deodara' added to Dataset (new size 11407 images)\n",
      "Folder 3 of 23 'Celtis sinensis' added to Dataset (new size 11431 images)\n",
      "Folder 4 of 23 'Cinnamomum camphora (Linn) Presl' added to Dataset (new size 11460 images)\n",
      "Folder 5 of 23 'Elaeocarpus decipiens' added to Dataset (new size 11483 images)\n",
      "Folder 6 of 23 'Flowering cherry' added to Dataset (new size 11496 images)\n",
      "Folder 7 of 23 'Ginkgo biloba' added to Dataset (new size 11524 images)\n",
      "Folder 8 of 23 'Koelreuteria paniculata' added to Dataset (new size 11552 images)\n",
      "Folder 9 of 23 'Lagerstroemia indica' added to Dataset (new size 11560 images)\n",
      "Folder 10 of 23 'Liquidambar formosana' added to Dataset (new size 11581 images)\n",
      "Folder 11 of 23 'Liriodendron chinense' added to Dataset (new size 11604 images)\n",
      "Folder 12 of 23 'Magnolia grandiflora L' added to Dataset (new size 11630 images)\n",
      "Folder 13 of 23 'Magnolia liliflora Desr' added to Dataset (new size 11654 images)\n",
      "Folder 14 of 23 'Michelia chapensis' added to Dataset (new size 11673 images)\n",
      "Folder 15 of 23 'Osmanthus fragrans' added to Dataset (new size 11695 images)\n",
      "Folder 16 of 23 'Photinia serratifolia' added to Dataset (new size 11710 images)\n",
      "Folder 17 of 23 'Platanus' added to Dataset (new size 11734 images)\n",
      "Folder 18 of 23 'Prunus cerasifera f. atropurpurea' added to Dataset (new size 11746 images)\n",
      "Folder 19 of 23 'Salix babylonica' added to Dataset (new size 11763 images)\n",
      "Folder 20 of 23 'Sapindus saponaria' added to Dataset (new size 11791 images)\n",
      "Folder 21 of 23 'Styphnolobium japonicum' added to Dataset (new size 11810 images)\n",
      "Folder 22 of 23 'Triadica sebifera' added to Dataset (new size 11829 images)\n",
      "Folder 23 of 23 'Zelkova serrata' added to Dataset (new size 11852 images)\n",
      "Dataset created with 11852 images\n"
     ]
    }
   ],
   "source": [
    "# All image folders from Urban Street Tree Dataset (classification)\n",
    "# test folder - 21 min\n",
    "# train folder - 2h 51 min\n",
    "# val folder - 20 min\n",
    "from build_dataset import build_dataset_from_folder\n",
    "\n",
    "folder_urbanstreet = 'C:\\\\Users\\\\viscom\\\\workspace\\\\tree_project\\\\tree_images\\\\UrbanStreet\\\\classification'\n",
    "folder_urbanstreet_test = os.path.join(folder_urbanstreet, 'test')\n",
    "folder_urbanstreet_train = os.path.join(folder_urbanstreet, 'train')\n",
    "folder_urbanstreet_val = os.path.join(folder_urbanstreet, 'val')\n",
    "\n",
    "build_dataset_from_folder(folder_urbanstreet_val, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buiding / extending dataset (using segmentation labels) (current size: 10874 images)\n",
      "Dataset created with 10997 images\n"
     ]
    }
   ],
   "source": [
    "# extra for Prunus class\n",
    "from build_dataset import build_dataset_using_segmentation_labels\n",
    "\n",
    "SEGM_DIR = \"C:\\\\Users\\\\viscom\\\\workspace\\\\tree_project\\\\tree_images\\\\UrbanStreet\\\\segmentation\\\\VOC2012\"\n",
    "SEGM_DIR_JPEG = os.path.join(SEGM_DIR,\"Prunus_JPEG\")\n",
    "SEGM_DIR_LABELS = os.path.join(SEGM_DIR,\"Prunus_Segm\")\n",
    "\n",
    "# DATASET_DIR_TEST = os.path.join(ROOT_DIR_GIS, 'photos','test_dataset')\n",
    "\n",
    "build_dataset_using_segmentation_labels(SEGM_DIR_JPEG, SEGM_DIR_LABELS, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buiding / extending dataset (using segmentation labels) (current size: 7048 images)\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (1).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (10).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (100).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (101).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (102).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (103).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (104).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (105).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (106).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (107).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (108).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (109).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (11).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (110).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (111).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (112).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (113).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (114).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (115).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (116).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (117).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (118).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (119).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (12).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (120).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (121).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (122).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (123).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (13).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (14).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (15).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (16).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (17).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (18).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (19).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (2).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (20).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (21).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (22).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (23).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (24).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (25).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (26).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (27).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (28).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (29).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (3).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (30).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (31).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (32).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (33).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (34).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (35).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (36).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (37).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (38).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (39).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (4).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (40).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (41).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (42).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (43).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (44).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (45).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (46).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (47).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (48).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (49).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (5).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (50).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (51).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (52).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (53).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (54).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (55).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (56).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (57).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (58).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (59).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (6).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (60).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (61).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (62).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (63).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (64).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (65).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (66).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (67).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (68).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (69).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (7).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (70).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (71).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (72).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (73).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (74).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (75).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (76).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (77).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (78).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (79).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (8).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (80).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (81).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (82).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (83).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (84).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (85).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (86).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (87).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (88).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (89).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (9).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (90).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (91).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (92).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (93).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (94).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (95).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (96).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (97).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (98).jpg: 'NoneType' object has no attribute 'shape'\n",
      "An error occurred in image C:\\Users\\viscom\\workspace\\tree_project\\tree_images\\UrbanStreet\\segmentation\\VOC2012\\JPEGImages\\Prunus cerasifera f. atropurpurea_tree_1 (99).jpg: 'NoneType' object has no attribute 'shape'\n",
      "Dataset created with 10874 images\n"
     ]
    }
   ],
   "source": [
    "from build_dataset import build_dataset_using_segmentation_labels\n",
    "\n",
    "SEGM_DIR = \"C:\\\\Users\\\\viscom\\\\workspace\\\\tree_project\\\\tree_images\\\\UrbanStreet\\\\segmentation\\\\VOC2012\"\n",
    "SEGM_DIR_JPEG = os.path.join(SEGM_DIR,\"JPEGImages\")\n",
    "SEGM_DIR_LABELS = os.path.join(SEGM_DIR,\"SegmentationClass\")\n",
    "\n",
    "build_dataset_using_segmentation_labels(SEGM_DIR_JPEG,SEGM_DIR_LABELS, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 10997/10997 [00:00<00:00, 14748.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/tree_dataset to C:/Users/viscom/.cache/huggingface/datasets/imagefolder/tree_dataset-46012d29d1c2057f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 10997/10997 [00:00<00:00, 21469.92it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to C:/Users/viscom/.cache/huggingface/datasets/imagefolder/tree_dataset-46012d29d1c2057f/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from build_dataset import generate_img_captions\n",
    "# 140 mins\n",
    "\n",
    "generate_img_captions(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset test & debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Resolving data files: 100%|██████████| 28/28 [00:00<?, ?it/s]\n",
      "Found cached dataset imagefolder (C:/Users/viscom/.cache/huggingface/datasets/imagefolder/test_s_dataset-8933df10b080af66/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "from build_dataset import generate_img_captions\n",
    "\n",
    "DATASET_S_DIR = os.path.join(ROOT_DIR_GIS, 'photos','test_s_dataset')\n",
    "generate_img_captions(DATASET_S_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\rembg\\sessions\\base.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  im_ary = im_ary / np.max(im_ary)\n",
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\rembg\\sessions\\u2net.py:29: RuntimeWarning: invalid value encountered in cast\n",
      "  mask = Image.fromarray((pred * 255).astype(\"uint8\"), mode=\"L\")\n",
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Apple added to Dataset (new size 28 images)\n",
      "Folder Banana added to Dataset (new size 56 images)\n",
      "Folder Lone tree istock images added to Dataset (new size 66 images)\n",
      "Folder orange added to Dataset (new size 89 images)\n",
      "Folder single tree image hd added to Dataset (new size 98 images)\n"
     ]
    }
   ],
   "source": [
    "# All images in input folder\n",
    "from build_dataset import build_dataset_from_folder\n",
    "\n",
    "in_folder = os.path.join(ROOT_DIR_GIS, 'photos','test')\n",
    "\n",
    "build_dataset_from_folder(in_folder, DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/viscom/.cache/huggingface/datasets/json/dataset-f2dc883c093bdb94/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'image', 'conditioning_image'],\n",
       "    num_rows: 9\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(DATASET_DIR, split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '',\n",
       " 'image': 'images/0.png',\n",
       " 'conditioning_image': 'conditioning_images/0.png'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Resolving data files: 100%|██████████| 98/98 [00:00<?, ?it/s]\n",
      "Found cached dataset imagefolder (C:/Users/viscom/.cache/huggingface/datasets/imagefolder/test_dataset-a3db2f81151b8a67/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer hardware business has been operating system software since its current owner's company.\n",
      "the most important thing in the world is to eat apples.\n",
      "a close up of a computer screen with a logo on it.\n",
      "computer hardware business has created a logo that can be seen in the dark.\n",
      "red apple with green leaf on a white background.\n",
      "computer hardware business on a blue background.\n",
      "computer hardware business has been making a logo for years\n",
      "computer hardware business - - the first logo in the world\n",
      "computer hardware business - - the first logo in the world\n",
      "icon with an apple on the screen\n",
      "a woman is standing in front of a logo.\n",
      "the logo is a symbol of the company's company.\n",
      "computer hardware business - - the logo for computer hardware business\n",
      "part of a black background\n",
      "a bunch of apples on a cutting board.\n",
      "the logo is a symbol of the company's logo.\n",
      "a red apple isolated on a white background\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a red and yellow apple on a white plate.\n",
      "the evolution of the apples\n",
      "computer hardware business has been working on the internet.\n",
      "computer hardware business has a logo that says the logo.\n",
      "banana with a wooden handle\n",
      "a bunch of bananas sitting on a blue surface.\n",
      "the logo is seen at the company's headquarters.\n",
      "a bunch of bananas sitting on top of a table.\n",
      "a pink background with a bunch of bananas\n",
      "a banana on a white background - - stock vector #\n",
      "a bunch of bananas on a stalk\n",
      "a bunch of bananas that are on a white background.\n",
      "a banana that is sitting on a table.\n",
      "a large bunch of bananas that are on a tree.\n",
      "a banana with a sticker on it\n",
      "a bunch of bananas on a white background\n",
      "a bunch of bananas with a cut out of it\n",
      "computer hardware business - - the apple of the future\n",
      "bananas and bananas in a bowl\n",
      "a ripe banana on a white background\n",
      "a banana on a blue background\n",
      "a bunch of ripe bananas on a wooden background.\n",
      "a bunch of ripe bananas on a wooden background.\n",
      "bananas and milk on a wooden cutting board\n",
      "a bunch of bananas on a white background\n",
      "a banana that has been cut into half.\n",
      "a bowl of sliced bananas and a banana\n",
      "drawing of a banana on a white background vector art illustration\n",
      "the speakers are designed to look like they are in a computer.\n",
      "bananas in the shape of heart\n",
      "sliced bananas and a knife on a cutting board\n",
      "a bunch of bananas hanging from a tree.\n",
      "a bunch of bananas on a white background\n",
      "a bunch of bananas sitting on top of a wooden table.\n",
      "a bunch of bananas in a cartoon style.\n",
      "a lone tree in a field of green grass.\n",
      "a tree in a field\n",
      "a lone tree in a field\n",
      "a lone tree in a green field\n",
      "the back of the iphone\n",
      "tree in a field with a yellow field royalty - free\n",
      "lonely tree in a field royalty - free\n",
      "a tree in a field in the middle of nowhere.\n",
      "a lone tree on the prairie royalty - free\n",
      "a tree in the sunset royalty - free\n",
      "a tree in a field\n",
      "a close up of an orange and a cut in half\n",
      "a pile of oranges with a cut in half.\n",
      "a whole orange with half and half of orange on a white background\n",
      "texture of an orange wall background\n",
      "a close up of a red apple on a table\n",
      "a close up of oranges in a pile\n",
      "the logo is a rectangle with a bright orange background.\n",
      "the orange is the color of the orange.\n",
      "a monitor in an orange background\n",
      "orange is the logo for the company\n",
      "a close up of an orange on a black background\n",
      "a slice of orange on a white background\n",
      "a slice of orange on a white background\n",
      "half of an orange on a white background\n",
      "a set of oranges on a white background.\n",
      "the logo is seen at the company's headquarters.\n",
      "oranges cut in half and cut into slices.\n",
      "a close up of a sliced orange on a table\n",
      "a picture of an orange with a slice stuck in it.\n",
      "a pile of oranges stacked on top of each other.\n",
      "a close up of a wall with orange light\n",
      "this is an orange cloth\n",
      "fresh oranges on a wooden table\n",
      "orange is the color of the orange.\n",
      "a pile of oranges on a table\n",
      "a lone tree stands in the middle of a field.\n",
      "computer hardware business has launched a new iphone x\n",
      "tree in a field of yellow\n",
      "a tree in a field in the middle of nowhere.\n",
      "a tree in a field with a blue sky and clouds\n",
      "a tree with no leaves on a hill\n",
      "a tree in a field with a green sky\n",
      "a tree in a field in the middle of nowhere.\n",
      "a lone tree on a green field with a blue sky\n",
      "a tree in a field of yellow flowers\n",
      "Image to tex:\n",
      "[{'generated_text': 'a blurry photo of a person with a black and white background '}]\n",
      "[{'generated_text': 'a fruit tree with apples and oranges '}]\n",
      "[{'generated_text': 'a white object with a black background '}]\n",
      "[{'generated_text': 'a blurry image of a colorful object '}]\n",
      "[{'generated_text': 'a red apple with a green apple on it '}]\n",
      "[{'generated_text': 'a small bird with a blue background '}]\n",
      "[{'generated_text': 'a black and white photo of a white and black cat '}]\n",
      "[{'generated_text': 'a blurry image of a black and white photo '}]\n",
      "[{'generated_text': 'a blurry image of a black and white photo '}]\n",
      "[{'generated_text': 'a clock with a picture of a person on it '}]\n",
      "[{'generated_text': 'a woman standing in front of a dark background '}]\n",
      "[{'generated_text': 'a cat is flying through the air with a kite '}]\n",
      "[{'generated_text': 'a black bird with a black face on it '}]\n",
      "[{'generated_text': 'a blurry photo of a street scene with a light '}]\n",
      "[{'generated_text': 'a knife and apples on a wooden cutting board '}]\n",
      "[{'generated_text': 'a black and white photo of a black and white bird '}]\n",
      "[{'generated_text': 'a red apple sitting on top of a white counter '}]\n",
      "[{'generated_text': 'a apple sitting on top of a white plate '}]\n",
      "[{'generated_text': 'a collection of different colored vases on a wall '}]\n",
      "[{'generated_text': 'a white bird is sitting on a white surface '}]\n",
      "[{'generated_text': 'a white clock with a picture of a cat on it '}]\n",
      "[{'generated_text': 'a banana is hanging from a yellow banana '}]\n",
      "[{'generated_text': 'bananas are sitting on a table '}]\n",
      "[{'generated_text': 'a large lamp with a black and white background '}]\n",
      "[{'generated_text': 'bananas hanging from a tree '}]\n",
      "[{'generated_text': 'a row of bananas with a picture of a person on them '}]\n",
      "[{'generated_text': 'a banana with a yellow and black border '}]\n",
      "[{'generated_text': 'a large bunch of green bananas hanging from a tree '}]\n",
      "[{'generated_text': 'bananas are hanging from a banana tree '}]\n",
      "[{'generated_text': 'a banana is sitting on a yellow surface '}]\n",
      "[{'generated_text': 'bananas hanging from a tree '}]\n",
      "[{'generated_text': 'a yellow and blue balloon with a yellow and blue background '}]\n",
      "[{'generated_text': 'bananas are sitting on a table '}]\n",
      "[{'generated_text': 'bananas and a banana peel '}]\n",
      "[{'generated_text': 'a colorful umbrella is in a picture '}]\n",
      "[{'generated_text': 'a bowl of bananas and a banana peel '}]\n",
      "[{'generated_text': 'a banana is sitting on a yellow background '}]\n",
      "[{'generated_text': 'a banana with a yellow and black border '}]\n",
      "[{'generated_text': 'bananas are sitting on a wooden table '}]\n",
      "[{'generated_text': 'bananas are sitting on a wooden table '}]\n",
      "[{'generated_text': 'a wooden cutting board with bananas and a knife '}]\n",
      "[{'generated_text': 'bananas are sitting on a table '}]\n",
      "[{'generated_text': 'a banana with a yellow peel on it '}]\n",
      "[{'generated_text': 'a bowl of bananas and a banana peel '}]\n",
      "[{'generated_text': 'a banana with a cartoon face on it '}]\n",
      "[{'generated_text': 'a white teddy bear sitting on top of a white object '}]\n",
      "[{'generated_text': 'a banana with a yellow and orange peel '}]\n",
      "[{'generated_text': 'a bowl of bananas and a spoon on a wooden surface '}]\n",
      "[{'generated_text': 'a banana tree with a bunch of bananas hanging from it '}]\n",
      "[{'generated_text': 'bananas are sitting on a table '}]\n",
      "[{'generated_text': 'bananas are sitting on a table '}]\n",
      "[{'generated_text': 'a banana is hanging from a banana tree '}]\n",
      "[{'generated_text': 'a tree in the middle of a field with a sky background '}]\n",
      "[{'generated_text': 'a tree in a field with a sky background '}]\n",
      "[{'generated_text': 'a lone bird is standing in the tall grass '}]\n",
      "[{'generated_text': 'a tree in the middle of a field '}]\n",
      "[{'generated_text': 'a black and white photo of a nintendo wii '}]\n",
      "[{'generated_text': 'a tree with a bunch of leaves on top of it '}]\n",
      "[{'generated_text': 'a grassy field with a tree and a sky background '}]\n",
      "[{'generated_text': 'a tree with a bunch of leaves on it '}]\n",
      "[{'generated_text': 'a tree in the middle of a field with a sky background '}]\n",
      "[{'generated_text': 'a tree with a sky background '}]\n",
      "[{'generated_text': 'a tree in the middle of a field with a sky background '}]\n",
      "[{'generated_text': 'a close up of an orange with a bite taken out '}]\n",
      "[{'generated_text': 'a close up of an orange with a lot of leaves '}]\n",
      "[{'generated_text': 'a close up of an orange with a bite taken out '}]\n",
      "[{'generated_text': 'a blurry photo of a blue sky '}]\n",
      "[{'generated_text': 'a pile of apples and a bunch of apples '}]\n",
      "[{'generated_text': 'a pile of oranges sitting on top of each other '}]\n",
      "[{'generated_text': 'a blue and yellow sign on a blue wall '}]\n",
      "[{'generated_text': 'a blurry photo of a blue and white vase '}]\n",
      "[{'generated_text': 'a blurry picture of a computer screen with a black background '}]\n",
      "[{'generated_text': 'a blue and white sign with a picture of a person '}]\n",
      "[{'generated_text': 'an orange is sitting on a table '}]\n",
      "[{'generated_text': 'a orange is cut in half with a knife '}]\n",
      "[{'generated_text': 'a orange is cut in half with a knife '}]\n",
      "[{'generated_text': 'a orange is cut in half with a knife '}]\n",
      "[{'generated_text': 'a pair of oranges sitting on top of a table '}]\n",
      "[{'generated_text': 'a blurry image of a sunset with a light '}]\n",
      "[{'generated_text': 'a pile of oranges sitting on top of each other '}]\n",
      "[{'generated_text': 'a orange sitting on a table with a knife '}]\n",
      "[{'generated_text': 'a close up of a picture of a orange '}]\n",
      "[{'generated_text': 'a pile of oranges sitting on top of each other '}]\n",
      "[{'generated_text': 'a blurry photo of a sunset with a clear sky '}]\n",
      "[{'generated_text': 'a close up of a blue and white photo of a red and white '}]\n",
      "[{'generated_text': 'a pile of oranges sitting on top of a wooden cutting board '}]\n",
      "[{'generated_text': 'a blurry picture of a blue and white object '}]\n",
      "[{'generated_text': 'a pile of oranges sitting on top of each other '}]\n",
      "[{'generated_text': 'a tree in the middle of a field with a sky background '}]\n",
      "[{'generated_text': 'a white computer mouse sitting on top of a white wall '}]\n",
      "[{'generated_text': 'a tree with a large amount of leaves on it '}]\n",
      "[{'generated_text': 'a tree with a large amount of leaves on it '}]\n",
      "[{'generated_text': 'a tree in the middle of a field '}]\n",
      "[{'generated_text': 'a tree in the middle of a field with a sky background '}]\n",
      "[{'generated_text': 'a tree with a large amount of leaves on it '}]\n",
      "[{'generated_text': 'a tree with a large leaf on it '}]\n",
      "[{'generated_text': 'a green field with a green tree and a green field '}]\n",
      "[{'generated_text': 'a tree in a field with a sky background '}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoProcessor\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import load_dataset, Image\n",
    "\n",
    "pipe = pipeline(model=\"microsoft/git-base-coco\", device=0)\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\", device=0)\n",
    "# img_filenames = [row['image'] for row in dataset['train']]\n",
    "\n",
    "dataset = load_dataset(path = DATASET_DIR, data_dir=\"images\" ,split=\"train\").cast_column(\"image\", Image())\n",
    "print(\"git-base-coco model:\")\n",
    "for out in pipe(KeyDataset(dataset, \"image\")):\n",
    "    print(out[0][\"generated_text\"])\n",
    "\n",
    "print(\"vit-gpt2-image-captioning model:\")\n",
    "for out2 in image_to_text(KeyDataset(dataset, \"image\")):\n",
    "    print(out2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-generating prompts with Image captioning\n",
    "https://huggingface.co/docs/transformers/main/model_doc/blip-2#transformers.Blip2ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Blip2ForConditionalGeneration(\n",
       "  (vision_model): Blip2VisionModel(\n",
       "    (embeddings): Blip2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (encoder): Blip2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-38): 39 x Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (qformer): Blip2QFormerModel(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): Blip2QFormerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (language_projection): Linear(in_features=768, out_features=2560, bias=True)\n",
       "  (language_model): OPTForCausalLM(\n",
       "    (model): OPTModel(\n",
       "      (decoder): OPTDecoder(\n",
       "        (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
       "        (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
       "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "              (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "            (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=50272, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a large tree in a field'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_caption(img_path):\n",
    "    # url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "    # image = Image.open(requests.get(url, stream=True).raw)\n",
    "    image = Image.open(img_path)\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    \n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=20)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "img_path = os.path.join(ROOT_DIR_GIS,'photos','tree','tree8.webp')\n",
    "generate_caption(img_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/Salesforce/blip-image-captioning-base#running-the-model-on-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' \n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "# conditional image captioning\n",
    "text = \"a photography of\"\n",
    "inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(processor.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a lone tree in a green field\n"
     ]
    }
   ],
   "source": [
    "# GIT (Generative Image-to-text Transformer) image captioning\n",
    "# https://huggingface.co/docs/transformers/main/model_doc/git#transformers.GitForCausalLM.forward.example\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/git-base-coco\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base-coco\")\n",
    "\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "img_path = os.path.join(ROOT_DIR_GIS,'photos','tree','tree8.webp')\n",
    "image = Image.open(img_path)\n",
    "\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\viscom\\\\workspace\\\\tree_project\\\\ControlNet-Trees\\\\Build_dataset'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "metadata_path = os.path.join(ROOT_DIR, \"train.jsonl\")\n",
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No config specified, defaulting to: treedataset/default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset treedataset/default to C:/Users/viscom/.cache/huggingface/datasets/treedataset/default/0.0.2/7c69bd2bbf56374c3ac175460302af8c1f41317322b9c0d3afaac8470e6ea473...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Specify the path to an existing ROOT_DIR of the tree dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n",
      "\u001b[0;32m      2\u001b[0m ROOT_DIR \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;32m      3\u001b[0m dataset_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR, \u001b[39m\"\u001b[39m\u001b[39mtree_dataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtreedataset.py\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m----> 4\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(dataset_path, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;32m      5\u001b[0m dataset\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\datasets\\load.py:1809\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n",
      "\u001b[0;32m   1806\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n",
      "\u001b[0;32m   1808\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n",
      "\u001b[1;32m-> 1809\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n",
      "\u001b[0;32m   1810\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n",
      "\u001b[0;32m   1811\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n",
      "\u001b[0;32m   1812\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n",
      "\u001b[0;32m   1813\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n",
      "\u001b[0;32m   1814\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n",
      "\u001b[0;32m   1815\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n",
      "\u001b[0;32m   1816\u001b[0m )\n",
      "\u001b[0;32m   1818\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n",
      "\u001b[0;32m   1819\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n",
      "\u001b[0;32m   1820\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n",
      "\u001b[0;32m   1821\u001b[0m )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\datasets\\builder.py:909\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n",
      "\u001b[0;32m    907\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m    908\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n",
      "\u001b[1;32m--> 909\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_and_prepare(\n",
      "\u001b[0;32m    910\u001b[0m         dl_manager\u001b[39m=\u001b[39mdl_manager,\n",
      "\u001b[0;32m    911\u001b[0m         verification_mode\u001b[39m=\u001b[39mverification_mode,\n",
      "\u001b[0;32m    912\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_split_kwargs,\n",
      "\u001b[0;32m    913\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs,\n",
      "\u001b[0;32m    914\u001b[0m     )\n",
      "\u001b[0;32m    915\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n",
      "\u001b[0;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\datasets\\builder.py:1670\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n",
      "\u001b[0;32m   1669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n",
      "\u001b[1;32m-> 1670\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_download_and_prepare(\n",
      "\u001b[0;32m   1671\u001b[0m         dl_manager,\n",
      "\u001b[0;32m   1672\u001b[0m         verification_mode,\n",
      "\u001b[0;32m   1673\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39mverification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS\n",
      "\u001b[0;32m   1674\u001b[0m         \u001b[39mor\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS,\n",
      "\u001b[0;32m   1675\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs,\n",
      "\u001b[0;32m   1676\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\venv\\lib\\site-packages\\datasets\\builder.py:982\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n",
      "\u001b[0;32m    980\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n",
      "\u001b[0;32m    981\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n",
      "\u001b[1;32m--> 982\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_generators(dl_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msplit_generators_kwargs)\n",
      "\u001b[0;32m    984\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n",
      "\u001b[0;32m    985\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\treedataset\\7c69bd2bbf56374c3ac175460302af8c1f41317322b9c0d3afaac8470e6ea473\\treedataset.py:43\u001b[0m, in \u001b[0;36mTreeDataset._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n",
      "\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split_generators\u001b[39m(\u001b[39mself\u001b[39m, dl_manager):\n",
      "\u001b[0;32m     42\u001b[0m     ROOT_DIR \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m~/treedataset\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m---> 43\u001b[0m     \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(ROOT_DIR), \u001b[39m\"\u001b[39m\u001b[39mSpecify the path to an existing ROOT_DIR of the tree dataset.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m     44\u001b[0m     metadata_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR, \u001b[39m\"\u001b[39m\u001b[39mtrain.jsonl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n",
      "\u001b[0;32m     47\u001b[0m         datasets\u001b[39m.\u001b[39mSplitGenerator(\n",
      "\u001b[0;32m     48\u001b[0m             name\u001b[39m=\u001b[39mdatasets\u001b[39m.\u001b[39mSplit\u001b[39m.\u001b[39mTRAIN,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     54\u001b[0m         ),\n",
      "\u001b[0;32m     55\u001b[0m     ]\n",
      "\n",
      "\u001b[1;31mAssertionError\u001b[0m: Specify the path to an existing ROOT_DIR of the tree dataset."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "dataset_path = os.path.join(ROOT_DIR, \"tree_dataset\", \"treedataset.py\")\n",
    "dataset = load_dataset(dataset_path, split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_path:  c:\\Users\\viscom\\workspace\\tree_project\\ControlNet-Trees\\tree_dataset\\train.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>image</th>\n",
       "      <th>conditioning_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the tree is a symbol of the world</td>\n",
       "      <td>images/0.png</td>\n",
       "      <td>conditioning_images/0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a tree with yellow leaves in autumn</td>\n",
       "      <td>images/1.png</td>\n",
       "      <td>conditioning_images/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>close up of a tree trunk</td>\n",
       "      <td>images/10.png</td>\n",
       "      <td>conditioning_images/10.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the sun shines through the trees.</td>\n",
       "      <td>images/100.png</td>\n",
       "      <td>conditioning_images/100.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>set of different trees on a transparent backgr...</td>\n",
       "      <td>images/1000.png</td>\n",
       "      <td>conditioning_images/1000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10992</th>\n",
       "      <td>a tree in the park</td>\n",
       "      <td>images/9995.png</td>\n",
       "      <td>conditioning_images/9995.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>a tree by the lake</td>\n",
       "      <td>images/9996.png</td>\n",
       "      <td>conditioning_images/9996.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>a tree by the lake</td>\n",
       "      <td>images/9997.png</td>\n",
       "      <td>conditioning_images/9997.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>a tree by the lake</td>\n",
       "      <td>images/9998.png</td>\n",
       "      <td>conditioning_images/9998.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>a willow tree on the banks</td>\n",
       "      <td>images/9999.png</td>\n",
       "      <td>conditioning_images/9999.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10997 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            image  \\\n",
       "0                      the tree is a symbol of the world     images/0.png   \n",
       "1                    a tree with yellow leaves in autumn     images/1.png   \n",
       "2                               close up of a tree trunk    images/10.png   \n",
       "3                      the sun shines through the trees.   images/100.png   \n",
       "4      set of different trees on a transparent backgr...  images/1000.png   \n",
       "...                                                  ...              ...   \n",
       "10992                                 a tree in the park  images/9995.png   \n",
       "10993                                 a tree by the lake  images/9996.png   \n",
       "10994                                 a tree by the lake  images/9997.png   \n",
       "10995                                 a tree by the lake  images/9998.png   \n",
       "10996                         a willow tree on the banks  images/9999.png   \n",
       "\n",
       "                 conditioning_image  \n",
       "0         conditioning_images/0.png  \n",
       "1         conditioning_images/1.png  \n",
       "2        conditioning_images/10.png  \n",
       "3       conditioning_images/100.png  \n",
       "4      conditioning_images/1000.png  \n",
       "...                             ...  \n",
       "10992  conditioning_images/9995.png  \n",
       "10993  conditioning_images/9996.png  \n",
       "10994  conditioning_images/9997.png  \n",
       "10995  conditioning_images/9998.png  \n",
       "10996  conditioning_images/9999.png  \n",
       "\n",
       "[10997 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata_path = os.path.join(os.path.dirname(dataset_path), \"train.jsonl\")\n",
    "print(\"metadata_path: \", metadata_path)\n",
    "pd.read_json(metadata_path, lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cn_trees",
   "language": "python",
   "name": "cn_trees"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
